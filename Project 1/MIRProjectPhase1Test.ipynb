{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BXCFFyc8Jnd7"
   },
   "source": [
    "<div dir=\"rtl\" style=\"direction:rtl;line-height:300%;text-align:justify;\" align=\"justify\"><font face=\"XB Zar\" size=5>\n",
    "<font color=red size=7>\n",
    "<p></p>\n",
    "<div align=center>توضیحات </div>\n",
    "</font>\n",
    "در این فایل قسمت هایی برای تست فاز اول پروژه قرار گرفته است. با اضافه شدن این قسمت ها به کد شما باید تمامی قسمت ها بدون اشکال اجرا شوند، در صورتی که شما فرضی به پروژه اضافه نکرده باشید و طبق استاندارد توضیح داده شده پیاده سازی کرده باشید، تمامی این قسمت ها بدون اشکال قابل اجرا هستند. اما در صورتی که قسمتی قابل اجرا نبود شما مجازید که با اعمال فرضیات خود کد تست را تغییر دهید تا تست ها به درستی اجرا شوند.\n",
    "پس از اعمال تغییرات مورد نیاز در همین فایل\n",
    "(بدون افزودن قسمت های قبلا پیاده سازی شده در پروژه)\n",
    "فایل را در سایت کوئرا آپلود کنید.  \n",
    "<strong>\n",
    "توجه کنید که تغییرات شما باید جزئی و صرفا در جهت ایجاد همخوانی در روند تست با فرضیات شما باشند، پس به هیچ عنوان نباید روند کلی تست ها را تغییر دهید! همچنین تمامی تغییرات و دلیل انجام آن ها را در همین فایل در سلول های مناسب شرح دهید.\n",
    "<br>\n",
    "همچنین هرگونه تغییر در تعداد ورودی ها و چیدمان آن ها غیر مجاز میباشد.\n",
    "</strong>\n",
    "</font></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BNtjLD_zM11t"
   },
   "source": [
    "<div style=\"direction:rtl;line-height:300%;text-align:justify;\" align=\"justify\"><font face=\"XB Zar\" size=2>\n",
    "<h1 dir=\"rtl\">قسمت اول و دوم<h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl;line-height:300%;text-align:justify;\" align=\"justify\"><font face=\"XB Zar\" size=2>\n",
    "<h1 dir=\"rtl\">سلام. کلیه فایل های xml و فولدر های queries و relevance باید در فولدر data در فولدر project1_data داده شده قرار بگیرند. هم چنین جهت اسلش ها برای من به شکل عکس گذاشته شده ی شما کار می کند و باید دو تا از هر کدام باشد یعنی من ادرس ها را به شکل project1_data\\\\\\data\\\\\\ تغییر داده ام. اگر نیاز داشتید می توانید جهت اسلش ها را اگر برایتان کار نمیکرد برگردانید اما اصل ادرس ها باید همین بماند. هم چنین خود فایل نوت بوک نیز کنار فولدر project1_data باید باشد. همان گونه که ضمیمه شده است.چند نکته دیگر نیز در سلول زیر گفته شده است<h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl;line-height:300%;text-align:justify;\" align=\"justify\"><font face=\"XB Zar\" size=2>\n",
    "<h1 dir=\"rtl\"> یکی این که قبل از این که سلول های تست رو روی کد من اجرا کنید، میدونید که باید سلول های مربوط به اون رو یک بار قبلش ران کنید. فقط برای دو بخش اضافه کردن داک و حذف کردن داک دو نکته وجود داره. یکی این که من فراخونی خود تابع رو توی سلول های خودم کامنت نکردم بنابراین قبل از اجرا کامنتش کنید چون تلاش می کنه یه فایلی که الان شما ندارید رو اضافه یا حذف کنه بنابراین ارور می خورید.\n",
    "     دوم این که برای اضافه و کم کردن داک، ادرس فایل گرفته شده تنها شامل یک داک هست (که به گفته خودتان در پیازا من دو فایل یکی شامل داک 3014 و دیگری شامل داک 6752 را ضمیمه خواهم کرد) و شماره داکی که نیز به عنوان ورودی می دهید شماره داک آن فایل در نظر گرفته شده و اگر از قبل موجود نبود آن داک به ایندکس افزوده می شود.\n",
    "      هم چنین در مورد تابع prepare text خروجی تابع لیستی از کلمات آن است<h1>\n",
    "</div>\n",
    "<div style=\"direction:rtl;line-height:300%;text-align:justify;\" align=\"justify\"><font face=\"XB Zar\" size=2>\n",
    "<h1 dir=\"rtl\"> در ضمن تابع مربوط به حذف داک به ادرس داک توجهی ندارد و تنها با شماره داک کار خواهد کرد.\n",
    "   در ضمن ادرس فایل هایی که با آن ها کار داریم با توجه به فولدرهایی که ضمیمه شده است در طول فایل تست تغییر کرده اند.\n",
    "    بنابراین هنگام اجرا فایل Persian.xml را نیز حتما درون فولدر data درون فولدر project1_data قرار دهید. <h1>\n",
    "</div>\n",
    "    <div style=\"direction:rtl;line-height:300%;text-align:justify;\" align=\"justify\"><font face=\"XB Zar\" size=2>\n",
    "<h1 dir=\"rtl\">در قسمت سیو و لود فایل نیز آدرسی که ذخیره در آن انجام می شود نیز تغییر کرده است.\n",
    "       save  خطی که تابع را صدا میزند در سلول من کامنت نشده بنابراین جهت جلوگیری از دو بار اتفاق افتادن این عملیات آن را کامنت کنید.\n",
    "   .\n",
    "    هم چنین در قسمت لود تابع من ایندکس جدید را خروجی داده و همان طور که در سلول من میبنید آن را در همان متغیر اندکس قبلی میریزم. بنابراین هنگام اجرا آن خط را کامنت کنید زیرا در کد تست زیر من خروجی صدا زدن تابع را در ایندکس میریزم.(خط فراخوانی تابع لود در تست زیر را تغییر دادم.)\n",
    "    در ضمن لطفا کد تست هر بخش را جدا ران کنید.<h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KdO8v3QCFDf_"
   },
   "outputs": [],
   "source": [
    "word1 = 'فکری'\n",
    "doc_id = 3014\n",
    "\n",
    "\n",
    "word2 = 'هیلاندراس'\n",
    "doc_id2 = 6752\n",
    "bigram = 'لا'\n",
    "\n",
    "def get_count (l):\n",
    "    i = [1 for _,t in l.items() for q in t['text']]\n",
    "    j = [1 for _,t in l.items() if 'title' in t.keys() for q in t['title']]\n",
    "    return len (i) + len(j)\n",
    "\n",
    "\n",
    "def test_prepare_text():\n",
    "    print (\"\\n============ testing 'prepare_text' =============================================\")\n",
    "    raw_text = \"کتابهای مناسبی نوشته شوند ! در راستای ارتقای . سطح آموزش کشور ؟ تلاش‌های زیادی صورت می‌گیرد\"\n",
    "    prepared_text = prepare_text(raw_text)\n",
    "    \n",
    "    print(\"prepared text is :\", prepared_text , \"with length:\" , len (prepared_text))\n",
    "    \n",
    "test_prepare_text()\n",
    "\n",
    "def test_get_posting_list():\n",
    "    \n",
    "    print (\"\\n============ testing 'get_posting_list' =========================================\")\n",
    "    \n",
    "    prepared_text = prepare_text(word1)[0]\n",
    "    posting_list = get_posting_list(prepared_text)\n",
    "    # posting_list = {3014:{'title':[...] , 'text':[...]}}\n",
    "    \n",
    "    \n",
    "#     print (\"posting list for input\" , prepared_text, \"is :\", posting_list , \"with length:\" , len (posting_list))\n",
    "    print (\"number of ocurrences of the word\", word1 , \" in documents = \", get_count (posting_list))\n",
    "    print ('docs with the word:' , sorted (list (posting_list.keys())))\n",
    "    \n",
    "test_get_posting_list()\n",
    "\n",
    "\n",
    "def test_bigram():\n",
    "    print (\"\\n============ testing 'get_words_with_bigram' ====================================\")\n",
    "    \n",
    "    words_with_bigram = get_words_with_bigram(bigram)\n",
    "    print (\"returned list length:\" , len (words_with_bigram))\n",
    "\n",
    "    print (\"checking word\" , word2 , \":\", word2 in words_with_bigram)\n",
    "    \n",
    "\n",
    "check_bigram = True\n",
    "if check_bigram:\n",
    "    test_bigram()\n",
    "\n",
    "def test_doc_remove():\n",
    "    \n",
    "    print (\"\\n============ testing 'doc_remove' ================================================\")\n",
    "    \n",
    "    posting_list = get_posting_list(prepare_text(word1)[0])\n",
    "    print (\"length of posting list for word\" , word1 , \"before removing doc\" , doc_id, \":\" , len (posting_list))\n",
    "    \n",
    "    delete_document_from_indexes('project1_data\\\\data\\\\3014.xml', doc_id)\n",
    "    \n",
    "    posting_list = get_posting_list(prepare_text(word1)[0])\n",
    "    print (\"length of posting list for word\" , word1 , \"after removing doc\" , doc_id, \":\" , len (posting_list))\n",
    "    \n",
    "    posting_list = get_posting_list(prepare_text(word2)[0])\n",
    "    print (\"length of posting list for word\" , word2 , \"before removing doc\" , doc_id2, \":\" , len (posting_list))\n",
    "    \n",
    "    delete_document_from_indexes('project1_data\\\\data\\\\6752.xml', doc_id2)\n",
    "    \n",
    "    posting_list = get_posting_list(prepare_text(word2)[0])\n",
    "    print (\"length of posting list for word\" , word2 , \"after removing doc\" , doc_id2, \":\" , len (posting_list))\n",
    "    \n",
    "test_doc_remove()\n",
    "\n",
    "def test_doc_remove_bigram():\n",
    "    print (\"\\n============ testing correct bigram removal ========================================\")\n",
    "    words_with_bigram = get_words_with_bigram(bigram)\n",
    "    print (\"returned list length:\" , len (words_with_bigram))\n",
    "    print (\"checking word\" , word2 , \":\", word2 in words_with_bigram)\n",
    "    \n",
    "\n",
    "if check_bigram:\n",
    "    test_doc_remove_bigram()\n",
    "\n",
    "def test_doc_add():\n",
    "    print (\"\\n============ testing 'doc_add' ================================================\")\n",
    "    \n",
    "    posting_list = get_posting_list(prepare_text(word1)[0])\n",
    "    print (\"length of posting list for word\" , word1 , \"before adding doc\" , doc_id, \":\" , len (posting_list))\n",
    "    print (\"number of ocurrences for \", word1, \":\", get_count (posting_list))\n",
    "    \n",
    "    add_document_to_indexes('project1_data\\\\data\\\\3014.xml', doc_id)\n",
    "    \n",
    "    posting_list = get_posting_list(prepare_text(word1)[0])\n",
    "    print (\"length of posting list for word\" , word1 , \"after adding doc\" , doc_id, \":\" , len (posting_list))\n",
    "    print (\"number of ocurrences for \", word1, \":\", get_count (posting_list))\n",
    "    \n",
    "    \n",
    "    posting_list = get_posting_list(prepare_text(word2)[0])\n",
    "    print (\"length of posting list for word\" , word2 , \"before adding doc\" , doc_id2, \":\" , len (posting_list))\n",
    "    \n",
    "    add_document_to_indexes('project1_data\\\\data\\\\6752.xml', doc_id2)\n",
    "    \n",
    "    posting_list = get_posting_list(prepare_text(word2)[0])\n",
    "    print (\"length of posting list for word\" , word2 , \"after adding doc\" , doc_id2, \":\" , len (posting_list))\n",
    "    \n",
    "    \n",
    "test_doc_add()\n",
    "\n",
    "\n",
    "def test_doc_add_bigram():\n",
    "    \n",
    "    words_with_bigram = get_words_with_bigram(bigram)\n",
    "    print (\"returned list length:\" , len (words_with_bigram))\n",
    "    print (\"checking word\" , word2 , \":\", word2 in words_with_bigram)\n",
    "\n",
    "if check_bigram:\n",
    "    test_doc_remove_bigram()\n",
    "    \n",
    "def test_save_and_load ():\n",
    "    print (\"\\n============ testing save and load methods ========================================\")\n",
    "    \n",
    "    destination = 'project1_data\\\\data\\\\index_backup.json'\n",
    "\n",
    "    posting_list = get_posting_list(prepare_text(word1)[0])\n",
    "    print (\"length of posting list for word\" , word1 , \"before saving:\" , len (posting_list))\n",
    "    print (\"number of ocurrences for \", word1, \":\", get_count (posting_list))\n",
    "    \n",
    "    save_index(destination)\n",
    "    main_index = load_index(destination)\n",
    "    \n",
    "    posting_list = get_posting_list(prepare_text(word1)[0])\n",
    "    print (\"length of posting list for word\" , word1 , \"after loading:\" , len (posting_list))\n",
    "    print (\"number of ocurrences for \", word1, \":\", get_count (posting_list))\n",
    "    \n",
    "test_save_and_load ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BNtjLD_zM11t"
   },
   "source": [
    "<div style=\"direction:rtl;line-height:300%;text-align:justify;\" align=\"justify\"><font face=\"XB Zar\" size=2>\n",
    "<h1 dir=\"rtl\">قسمت سوم<h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl;line-height:300%;text-align:justify;\" align=\"justify\"><font face=\"XB Zar\" size=2>\n",
    "<h1 dir=\"rtl\">در قسمت تصحیح query نیز خط صدا زدن تابع را در سلول من کامنت کنید که دو بار این اتفاق نیفتد.\n",
    "    ببخشید که در کل فایل من احتمالا خط های فراخوانی توابع را باید کامنت کنید و من این کار را نکردم.<h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zGxtv7qZM90t"
   },
   "outputs": [],
   "source": [
    "def test_correct_query():\n",
    "\n",
    "    ##################################\n",
    "    ## Do not change this part\n",
    "    ##################################\n",
    "    query = 'ابذار های فظایی و پیشرفته ناصا'\n",
    "    ##################################\n",
    "    \n",
    "    result = correct_query(query)\n",
    "    print(result)\n",
    "\n",
    "test_correct_query()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl;line-height:300%;text-align:justify;\" align=\"justify\"><font face=\"XB Zar\" size=2>\n",
    "<h1 dir=\"rtl\">\n",
    "    برای بخش سرچ دو سلول هست که باید  ران بشن تا نوت بوک توابع رو بفهمه. هم چنین باز هم خط صدا زدن تابع سرچ در سلول دوم من را کامنت کنید \n",
    "     عددی که علاوه بر لیست چاپ می شود طول لیست است\n",
    "    این به این خاطر است که من فراموش کردم این خط کد که این موضوع را چاپ می کند بردارم. این خط خط شماره ۸ تابع search من است و برای بخش های اینده اگر می شود خودتان کامنت کنید.<h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A9n-4JRDNDcS"
   },
   "outputs": [],
   "source": [
    "def test_search():\n",
    "\n",
    "    ##################################\n",
    "    ## Do not change this part\n",
    "    ##################################\n",
    "    query = 'سیاره های بزرگ \"منظومه شمسی\"'\n",
    "    method = \"ltc-lnc\"\n",
    "    ##################################\n",
    "\n",
    "    relevant_docs = search(query, method)\n",
    "    print(relevant_docs)\n",
    "\n",
    "test_search()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl;line-height:300%;text-align:justify;\" align=\"justify\"><font face=\"XB Zar\" size=2>\n",
    "<h1 dir=\"rtl\">در این بخش سرچ با جزییات هم خط صدا زدن تابع در سلول من را کامنت کنید<h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fi_cziuINH8x"
   },
   "outputs": [],
   "source": [
    "def test_detailed_search():\n",
    "    \n",
    "    ##################################\n",
    "    ## Do not change this part\n",
    "    ##################################\n",
    "    title_query = 'فهرست شهرهای ایران'\n",
    "    text_query = 'استان گیلان شهرستان لنگرود'\n",
    "    ##################################\n",
    "\n",
    "    relevant_docs = detailed_search(title_query, text_query)\n",
    "    print(relevant_docs)\n",
    "\n",
    "test_detailed_search()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ePcovk3jG8aG"
   },
   "source": [
    "<div style=\"direction:rtl;line-height:300%;text-align:justify;\" align=\"justify\"><font face=\"XB Zar\" size=2>\n",
    "<h1 dir=\"rtl\">قسمت چهارم<h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vidL0GkdHmBA"
   },
   "source": [
    "<div dir=\"rtl\" style=\"direction:rtl;line-height:300%;text-align:justify;\" align=\"justify\"><font face=\"XB Zar\" size=5>\n",
    "در این قسمت به دلیل استفاده از utf8\n",
    "در فایل های داده، در بعضی از کد های ارسال شده پردازش فایل ها با خطا مواجه میشود برای حل این مشکل بدون دست بردن در کد های ارسال شده میتوانیم از سلول زیر استفاده کنیم.  \n",
    "درصورتی که شما نیازی به اعمال این تغییر ندارید میتوانید این سلول را در تست خود اجرا نکنید.\n",
    "<strong>\n",
    "در صورتی که نیاز به ایجاد تغییر در این سلول دارید حتما تغییرات خود را در یک سلول متنی شرح دهید!!!\n",
    "</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl;line-height:300%;text-align:justify;\" align=\"justify\"><font face=\"XB Zar\" size=2>\n",
    "<h1 dir=\"rtl\">من نیازی به سلول گفته شده ندارم<h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MPyzE_xlFDgG",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    python_open\n",
    "    print(\"Already done!\")\n",
    "except NameError:\n",
    "    python_open = open\n",
    "    def open(file, mode='r', buffering=-1, encoding=None, errors=None, newline=None, closefd=True, opener=None):\n",
    "        encoding=\"utf-8\"\n",
    "        return python_open(file, mode=mode, buffering=buffering, encoding=encoding, errors=errors, newline=newline, closefd=closefd, opener=opener)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl;line-height:300%;text-align:justify;\" align=\"justify\"><font face=\"XB Zar\" size=2>\n",
    "<h1 dir=\"rtl\">علاوه بر نتایج خواسته شده طول لیست جواب هر query نیز چاپ می شود\n",
    "    ببخشید من فراموش کردم خط مربوطه بهش رو کامنت کنم. و همون طور که در خود تابع سرچ طول لیست چاپ شد این جا هم چاپ می شود.\n",
    "    همان طور که در بخش سرچ گفته شد اگه خودتان خط مربوطه را کامنت کنید دیگر چاپ نمیشوند.\n",
    "    هم چنین در پیاده سازی معیار MAP میانگین روی داک های مرتبط برگدانده شده انجام شده است نه روی کل داک های مرتبط. این کار به دلیل آن است که کلیه مثال های اسلاید در هر دوحالت جوابشان یکسان بوده و واقعا این تفاوت قابل تشخیص نبود و باعث ابهام من شد.\n",
    "    هم چنین معیار R-precision نیز حاصل به دست آمده به اشتباه به جای تقسیم بر تعداد داک های برگردانده شده به تعداد کل داک های مرتبط تقسیم شده است.<h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LOLBO7uMFDgK"
   },
   "outputs": [],
   "source": [
    "##################################\n",
    "## Do not change this part\n",
    "##################################\n",
    "test_docs = ['all', 1, 2, 3]\n",
    "functions = {'R_Precision':R_Precision, 'F_measure':F_measure, 'MAP':MAP, 'NDCG': NDCG}\n",
    "##################################\n",
    "\n",
    "for doc in test_docs:\n",
    "    print(\"{}\\ndoc:\\t{}\".format('-'*30, doc))\n",
    "    for f in functions.keys():\n",
    "        out = functions[f](doc)\n",
    "        print(\"{:11}:\\t{:.2f}\".format(f, out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a3CaHWJKJVcH"
   },
   "source": [
    "<div dir=\"rtl\" style=\"direction:rtl;line-height:300%;text-align:justify;\" align=\"justify\"><font face=\"XB Zar\" size=5>\n",
    "نمونه خروجی:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "39oS5a9AFDgN"
   },
   "source": [
    "------------------------------\n",
    "    doc:\tall\n",
    "    R_Precision:\t0.73\n",
    "    F_measure  :\t0.65\n",
    "    MAP        :\t0.63\n",
    "    NDCG       :\t0.75\n",
    "    \n",
    "------------------------------\n",
    "    doc:\t1\n",
    "    R_Precision:\t1.00\n",
    "    F_measure  :\t0.97\n",
    "    MAP        :\t0.94\n",
    "    NDCG       :\t0.96\n",
    "    \n",
    "------------------------------\n",
    "    doc:\t2\n",
    "    R_Precision:\t1.00\n",
    "    F_measure  :\t0.91\n",
    "    MAP        :\t0.83\n",
    "    NDCG       :\t0.90\n",
    "    \n",
    "------------------------------\n",
    "    doc:\t3\n",
    "    R_Precision:\t0.73\n",
    "    F_measure  :\t0.49\n",
    "    MAP        :\t0.29\n",
    "    NDCG       :\t0.48"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M3vMlLNSJafk"
   },
   "source": [
    "<div dir=\"rtl\" style=\"direction:rtl;line-height:300%;text-align:justify;\" align=\"justify\"><font face=\"XB Zar\" size=5>\n",
    "در این قسمت توابع امتیاز دهی شما مستقل از سایر قسمت های پروژه تست میشوند. برای این کار توابع جستجو مجددا با ساختار ساده ای پیاده سازی شده اند تا خروجی ثابتی را تولید کنند.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl;line-height:300%;text-align:justify;\" align=\"justify\"><font face=\"XB Zar\" size=2>\n",
    "<h1 dir=\"rtl\">در قسمت زیر تابع های سرچ کمی تغییر کرده اند تا حداکثر 15 نتیجه دهند.\n",
    "    حالتی که مخرج f measure صفر شود هندل نشده است بنابراین ارور تقسیم بر صفر میدهد لطفا هر بخش را جدا ران کنید. سایر بخش ها بدون ارور هستند.<h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rKPkT5jEFDgN",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##################################\n",
    "## Do not change this part\n",
    "##################################\n",
    "test_docs = [1, 2, 3]\n",
    "rels = [\n",
    "    [6753, 7134, 6978, 7136, 4530, 6798, 6885, 5381, 6900, 4537, 5509, 6794, 4094, 6417, 3666, 5967],\n",
    "    [6753, 5509, 4718, 6798, 6850, 6417, 6978, 6871],\n",
    "    list(range(20))\n",
    "]\n",
    "outputs = [{'R_Precision': 1.0, 'F_measure': 0.967741935483871, 'MAP': 0.9375, 'NDCG': 0.9635640110263509},\n",
    "           {'R_Precision': 0.4444444444444444, 'F_measure': 0.6153846153846153, 'MAP': 0.4444444444444444, 'NDCG': 0.6313802022799658},\n",
    "           {'R_Precision': 0.0, 'F_measure': 0.0, 'MAP': 0.0, 'NDCG': 0.0}]\n",
    "\n",
    "functions = {'R_Precision':R_Precision, 'F_measure':F_measure, 'MAP':MAP, 'NDCG': NDCG}\n",
    "##################################\n",
    "idx = 0 \n",
    "\n",
    "ds = detailed_search\n",
    "s = search\n",
    "def detailed_search(title_query, text_query, method=\"ltn-lnn\"):\n",
    "    t = min(len(rels[idx]), 15)\n",
    "    return rels[idx][0:t]\n",
    "\n",
    "def search(query, method=\"ltn-lnn\", weight=2):\n",
    "    t = min(len(rels[idx]), 15)\n",
    "    return rels[idx][0:t]\n",
    "\n",
    "for f in functions.keys():\n",
    "    print(\"{}\\n{}:\".format('-'*30, f))\n",
    "    idx = 0\n",
    "    for doc in test_docs:    \n",
    "        out = functions[f](doc)\n",
    "        expected = outputs[idx][f]\n",
    "        print(\"{}:\\t{:.2f}\\t{}\".format(doc, out, abs(out-expected)<1e-3))\n",
    "        idx += 1\n",
    "\n",
    "detailed_search = ds\n",
    "search = s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JVFa3UbdJ_5W"
   },
   "source": [
    "<div dir=\"rtl\" style=\"direction:rtl;line-height:300%;text-align:justify;\" align=\"justify\"><font face=\"XB Zar\" size=5>\n",
    "نمونه خروجی:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m8vPRt7GFDgS"
   },
   "source": [
    "------------------------------\n",
    "    R_Precision: \n",
    "    1:\t1.00\tTrue \n",
    "    2:\t0.44\tTrue \n",
    "    3:\t0.00\tTrue \n",
    "    \n",
    "------------------------------\n",
    "    F_measure: \n",
    "    1:\t0.97\tTrue\n",
    "    2:\t0.62\tTrue\n",
    "    3:\t0.00\tTrue\n",
    "\n",
    "------------------------------\n",
    "    MAP: \n",
    "    1:\t0.94\tTrue\n",
    "    2:\t0.44\tTrue\n",
    "    3:\t0.00\tTrue\n",
    "\n",
    "------------------------------\n",
    "    NDCG:\n",
    "    1:\t0.96\tTrue\n",
    "    2:\t0.63\tTrue\n",
    "    3:\t0.00\tTrue\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "colab": {
   "collapsed_sections": [],
   "name": "MIRProjectPhase1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
